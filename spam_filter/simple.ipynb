{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Jupyter notebook sample"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "To build a system to classify messages as spam or not spam, we need to start with a labelled dataset of what people already consider spam. There is a labelled dataset at \n",
    "\n",
    "https://dq-content.s3.amazonaws.com/433/SMSSpamCollection\n",
    "\n",
    "We'll read it in and start building a system to use a naive bayes spam filter"
   ],
   "id": "ff00d2c043a7df57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:28:43.100211Z",
     "start_time": "2024-10-04T04:28:43.097717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "id": "7df9140457caed5e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:28:44.781321Z",
     "start_time": "2024-10-04T04:28:43.109236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read in the data, process it a little\n",
    "data_set = \"https://dq-content.s3.amazonaws.com/433/SMSSpamCollection\"\n",
    "data = pd.read_csv(data_set, header=None, names=['Label', 'SMS'], sep='\\t')\n",
    "# We want a random seed\n",
    "seed = 1\n"
   ],
   "id": "78bc79986cf5dac9",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With the data set loaded, lets explore it",
   "id": "8c10d5fa24e7c904"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:28:44.817355Z",
     "start_time": "2024-10-04T04:28:44.812370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(data.shape)\n",
    "print(data.head(5))\n",
    "data[\"Label\"].value_counts()\n"
   ],
   "id": "2675a2f856682c77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "  Label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:28:44.863968Z",
     "start_time": "2024-10-04T04:28:44.860239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spam_ratio = data[\"Label\"].value_counts(normalize=True)[\"spam\"] / data[\"Label\"].value_counts(normalize=True)[\n",
    "    \"ham\"] * 100\n",
    "print(f'The ratio of spam messages is {spam_ratio:.2f}%')"
   ],
   "id": "dbad64c2cd6c2768",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of spam messages is 15.48%\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "There's 747 spam messages and 4825 'ham' (non-spam) messages\n",
    "\n",
    "## Building training and test sets\n",
    "We need to split this labelled data set into a training set using about 80% of the data, and a test set, by which we'll validate the classification filter. We'll aim for 80% accuracy of the spam filter. Fortunate the scikit-learn module has a function for exactly this purpose\n"
   ],
   "id": "1faa823fa1fe56f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:28:44.895953Z",
     "start_time": "2024-10-04T04:28:44.889569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'data' is your dataset DataFrame and the target column is labeled as 'label'\n",
    "\n",
    "# Split the dataset into training (80%) and test (20%) sets\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=seed)\n",
    "\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "test_set = test_set.reset_index(drop=True)\n",
    "\n",
    "# Calculate percentage of 'spam' and 'ham' in the full dataset\n",
    "full_spam_percentage = (data['Label'].value_counts()['spam'] / len(data)) * 100\n",
    "full_ham_percentage = (data['Label'].value_counts()['ham'] / len(data)) * 100\n",
    "\n",
    "# Calculate percentage of 'spam' and 'ham' in the training set\n",
    "train_spam_percentage = (train_set['Label'].value_counts()['spam'] / len(train_set)) * 100\n",
    "train_ham_percentage = (train_set['Label'].value_counts()['ham'] / len(train_set)) * 100\n",
    "\n",
    "# Calculate percentage of 'spam' and 'ham' in the test set\n",
    "test_spam_percentage = (test_set['Label'].value_counts()['spam'] / len(test_set)) * 100\n",
    "test_ham_percentage = (test_set['Label'].value_counts()['ham'] / len(test_set)) * 100\n",
    "\n",
    "# Output the percentages\n",
    "percentages_df = pd.DataFrame({\n",
    "        \"Full dataset\": [full_spam_percentage, full_ham_percentage],\n",
    "        \"Training set\": [train_spam_percentage, train_ham_percentage],\n",
    "        \"Test set\"    : [test_spam_percentage, test_ham_percentage]\n",
    "}, index=[\"spam\", \"ham\"]\n",
    ")\n",
    "\n",
    "print(percentages_df)\n"
   ],
   "id": "a83c3ce2acceaae9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Full dataset  Training set   Test set\n",
      "spam     13.406317      13.46197  13.183857\n",
      "ham      86.593683      86.53803  86.816143\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see we've generated the data sets and the ratio of spam to non spam remains about the same, so it should be fine for our purposes\n",
    "\n",
    "## Splitting messages into discrete words\n",
    "Now we need to process all the strings in the message to split them out into discrete words for the naive bayes filter."
   ],
   "id": "3948c1338b9d29ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:28:44.980171Z",
     "start_time": "2024-10-04T04:28:44.977491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sms_string_to_words(message):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    return message.split()\n",
    "\n",
    "\n",
    "# Extract sample messages from the 'sms' column of the training set\n",
    "sample_sms = train_set['SMS'].head(5)  # Extract the first 5 messages as test cases\n",
    "\n",
    "# Apply the function to each sample and print the result\n",
    "for i, sms in enumerate(sample_sms):\n",
    "    print(f\"Original SMS {i + 1}: {sms}\")\n",
    "    words = sms_string_to_words(sms)\n",
    "    print(f\"Processed SMS {i + 1}: {words}\\n\")"
   ],
   "id": "f2e9e84c07c02064",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original SMS 1: Hi , where are you? We're at  and they're not keen to go out i kind of am but feel i shouldn't so can we go out tomo, don't mind do you?\n",
      "Processed SMS 1: ['hi', 'where', 'are', 'you', 'we', 're', 'at', 'and', 'they', 're', 'not', 'keen', 'to', 'go', 'out', 'i', 'kind', 'of', 'am', 'but', 'feel', 'i', 'shouldn', 't', 'so', 'can', 'we', 'go', 'out', 'tomo', 'don', 't', 'mind', 'do', 'you']\n",
      "\n",
      "Original SMS 2: If you r @ home then come down within 5 min\n",
      "Processed SMS 2: ['if', 'you', 'r', 'home', 'then', 'come', 'down', 'within', '5', 'min']\n",
      "\n",
      "Original SMS 3: When're you guys getting back? G said you were thinking about not staying for mcr\n",
      "Processed SMS 3: ['when', 're', 'you', 'guys', 'getting', 'back', 'g', 'said', 'you', 'were', 'thinking', 'about', 'not', 'staying', 'for', 'mcr']\n",
      "\n",
      "Original SMS 4: Tell my  bad character which u Dnt lik in me. I'll try to change in  &lt;#&gt; . I ll add tat 2 my new year resolution. Waiting for ur reply.Be frank...good morning.\n",
      "Processed SMS 4: ['tell', 'my', 'bad', 'character', 'which', 'u', 'dnt', 'lik', 'in', 'me', 'i', 'll', 'try', 'to', 'change', 'in', 'lt', 'gt', 'i', 'll', 'add', 'tat', '2', 'my', 'new', 'year', 'resolution', 'waiting', 'for', 'ur', 'reply', 'be', 'frank', 'good', 'morning']\n",
      "\n",
      "Original SMS 5: I'm leaving my house now...\n",
      "Processed SMS 5: ['i', 'm', 'leaving', 'my', 'house', 'now']\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The function is successfully extracting the words, but it's splitting words when an apostrophe would be used. I'm becomes I m\n",
    "\n",
    "This shouldn't be much of a problem, but could present some bias in the training data if the randomly selected 80% of the messages contain more people that use contractions compared to those that don't"
   ],
   "id": "23572ac12504391c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:28:45.072737Z",
     "start_time": "2024-10-04T04:28:45.036885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set['SMS'] = train_set['SMS'].str.replace(r'[^\\w]', ' ', regex=True)\n",
    "train_set['SMS'] = train_set['SMS'].str.lower()\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for message in train_set['SMS']:\n",
    "    for word in sms_string_to_words(message):\n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary_set = set(vocabulary)\n",
    "vocabulary_list = list(vocabulary_set)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vocabulary_list)}\")\n",
    "print(f\"Sample vocabulary words: {vocabulary_list[:20]}\")"
   ],
   "id": "fec009097c60681f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 7753\n",
      "Sample vocabulary words: ['87077', '82277', 'difficult', 'bimbo', 'testing', 'cn', 'imma', 'q', 'slippery', 'timings', 'stopbcm', 'bcm4284', 'mon', 'weaseling', 'argh', 'stylish', 'previews', 'sweatter', 'act', 'gift']\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:28:45.084288Z",
     "start_time": "2024-10-04T04:28:45.082246Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bf274390ec965939",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:28:49.282549Z",
     "start_time": "2024-10-04T04:28:45.114645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(train_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(train_set['SMS']):\n",
    "    for word in sms_string_to_words(sms):\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "\n",
    "# Now transforming the word_counts_per_sms dictionary into a DataFrame\n",
    "word_counts_df = pd.DataFrame(word_counts_per_sms).fillna(0)\n",
    "\n",
    "# Concatenate this DataFrame with the original train_set DataFrame\n",
    "train_set_clean = pd.concat([train_set, word_counts_df], axis=1)\n",
    "\n",
    "train_set_clean.shape\n"
   ],
   "id": "d9736be6e7bc160c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 7755)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:28:49.345415Z",
     "start_time": "2024-10-04T04:28:49.343886Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c74f32c2a18aa00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that the training data is cleaned and ready, need to write the functions that calculate probabilities of spam and non-spam. First lets define all the constants going to be used",
   "id": "aea4ed337a802c9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:29:47.037062Z",
     "start_time": "2024-10-04T04:29:46.904578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_messages = len(train_set_clean)\n",
    "spam_messages = train_set_clean[train_set_clean['Label'] == 'spam']\n",
    "ham_messages = train_set_clean[train_set_clean['Label'] == 'ham']\n",
    "\n",
    "P_spam = len(spam_messages) / total_messages\n",
    "P_ham = len(ham_messages) / total_messages\n",
    "\n",
    "# Step 2: Calculate NSpam (total number of words in spam messages)\n",
    "N_words_per_spam = train_set_clean[train_set_clean['Label'] == 'spam']['SMS'].apply(len)\n",
    "N_spam = N_words_per_spam.sum()\n",
    "\n",
    "# Step 3: Calculate NHam (total number of words in ham messages)\n",
    "N_words_per_ham = train_set_clean[train_set_clean['Label'] == 'ham']['SMS'].apply(len)\n",
    "N_ham = N_words_per_ham.sum()\n",
    "\n",
    "N_vocabulary = len(vocabulary)\n",
    "\n",
    "# Step 5: Initialize alpha\n",
    "alpha = 1\n",
    "\n",
    "# Results summary\n",
    "results = {\n",
    "        \"P(Spam)\"    : P_spam,\n",
    "        \"P(Ham)\"     : P_ham,\n",
    "        \"NSpam\"      : N_spam,\n",
    "        \"NwSpam\"     : N_words_per_spam,\n",
    "        \"NwHam\"      : N_words_per_ham,\n",
    "        \"NHam\"       : N_ham,\n",
    "        \"NVocabulary\": N_vocabulary,\n",
    "        \"Alpha\"      : alpha\n",
    "}"
   ],
   "id": "b29bb2c1f13f8dc5",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a8405f4299b2092b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T04:33:33.783429Z",
     "start_time": "2024-10-04T04:32:17.181733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize two dictionaries for P(wi|Spam) and P(wi|Ham) with vocabulary words as keys and 0 as the initial value\n",
    "P_wi_given_spam = {word: 0 for word in vocabulary}\n",
    "P_wi_given_ham = {word: 0 for word in vocabulary}\n",
    "\n",
    "# Isolate spam and ham messages into two different DataFrames\n",
    "spam_messages_df = train_set_clean[train_set_clean['Label'] == 'spam']\n",
    "ham_messages_df = train_set_clean[train_set_clean['Label'] == 'ham']\n",
    "\n",
    "\n",
    "# Function to count the occurrences of a word in a DataFrame of messages\n",
    "def count_word_occurrences(word, df):\n",
    "    return df['SMS'].apply(lambda message: message.count(word)).sum()\n",
    "\n",
    "\n",
    "# Calculate P(wi|Spam) and P(wi|Ham) for each word in the vocabulary\n",
    "for word in vocabulary:\n",
    "    Nwi_spam = count_word_occurrences(word, spam_messages_df)\n",
    "    Nwi_ham = count_word_occurrences(word, ham_messages_df)\n",
    "\n",
    "    # Calculate P(wi|Spam) and P(wi|Ham) using the formulas\n",
    "    P_wi_given_spam[word] = (Nwi_spam + alpha) / (N_spam + alpha * N_vocabulary)\n",
    "    P_wi_given_ham[word] = (Nwi_ham + alpha) / (N_ham + alpha * N_vocabulary)\n",
    "\n",
    "# Output the first few values of each dictionary for inspection\n",
    "P_wi_given_spam_sample = {k: P_wi_given_spam[k] for k in list(P_wi_given_spam)[:5]}\n",
    "P_wi_given_ham_sample = {k: P_wi_given_ham[k] for k in list(P_wi_given_ham)[:5]}"
   ],
   "id": "1287f6a037c6de3e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T05:18:24.432082Z",
     "start_time": "2024-10-04T05:18:24.428418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def classify_message(message):\n",
    "    # clean the message\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = P_spam\n",
    "    p_ham_given_message = P_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in P_wi_given_spam:\n",
    "            p_spam_given_message *= P_wi_given_spam[word]\n",
    "        \n",
    "        if word in P_wi_given_ham:\n",
    "            p_ham_given_message *= P_wi_given_ham[word]\n",
    "    \n",
    "    if p_spam_given_message > p_ham_given_message:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"ham\"\n",
    "\n",
    "\n",
    "classify_message(\"WINNER!! This is the secret code to unlock the money: C3421.\")\n",
    "\n"
   ],
   "id": "58519bb25cfa6da2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T05:20:44.530321Z",
     "start_time": "2024-10-04T05:20:44.527450Z"
    }
   },
   "cell_type": "code",
   "source": "classify_message(\"Sounds good, Tom, then see u there\")",
   "id": "95a0cd48d5edbc0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "16c407af0f9a013f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T05:22:37.253496Z",
     "start_time": "2024-10-04T05:22:37.250561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_test_set(message):\n",
    "    # clean the message\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "\n",
    "    p_spam_given_message = P_spam\n",
    "    p_ham_given_message = P_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in P_wi_given_spam:\n",
    "            p_spam_given_message *= P_wi_given_spam[word]\n",
    "\n",
    "        if word in P_wi_given_ham:\n",
    "            p_ham_given_message *= P_wi_given_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ],
   "id": "c13625683aa67989",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T05:22:38.727642Z",
     "start_time": "2024-10-04T05:22:38.716410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_set['Prediction'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head(10)"
   ],
   "id": "a3a3b95afeb3786b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Label                                                SMS Prediction\n",
       "0   ham                       Yep, by the pretty sculpture        ham\n",
       "1   ham      Yes, princess. Are you going to make me moan?        ham\n",
       "2   ham                         Welp apparently he retired        ham\n",
       "3   ham                                            Havent.        ham\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ...        ham\n",
       "5   ham  Ok i thk i got it. Then u wan me 2 come now or...        ham\n",
       "6   ham  I want kfc its Tuesday. Only buy 2 meals ONLY ...        ham\n",
       "7   ham                         No dear i was sleeping :-P        ham\n",
       "8   ham                          Ok pa. Nothing problem:-)        ham\n",
       "9   ham                    Ill be there on  &lt;#&gt;  ok.        ham"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok i thk i got it. Then u wan me 2 come now or...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>I want kfc its Tuesday. Only buy 2 meals ONLY ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>No dear i was sleeping :-P</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok pa. Nothing problem:-)</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ill be there on  &amp;lt;#&amp;gt;  ok.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T05:25:12.400432Z",
     "start_time": "2024-10-04T05:25:12.385015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correct = 0\n",
    "total = len(test_set)\n",
    "\n",
    "for index, row in test_set.iterrows():\n",
    "    prediction = row['Prediction']\n",
    "    actual_label = row['Label']\n",
    "    \n",
    "    if prediction == actual_label:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(accuracy)"
   ],
   "id": "ba9ef2c5584e8d43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9883408071748879\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The filter was 98.8% accurate, ",
   "id": "38103054272512a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
